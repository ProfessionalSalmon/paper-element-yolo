{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5ba7f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.163 ðŸš€ Python-3.12.3 torch-2.7.1+cu126 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "Setup complete âœ… (12 CPUs, 7.6 GB RAM, 244.3/1006.9 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab3d4c",
   "metadata": {},
   "source": [
    "### Load dataset from Roboflow workspace\n",
    "1. Go to your Roboflow dashboard: https://app.roboflow.com/\n",
    "2. Look at the URL when you're in your project\n",
    "3. The URL format is: https://app.roboflow.com/[WORKSPACE_NAME]/[PROJECT_NAME]/[VERSION]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedd1376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dataset downloaded to: /home/terra/projects/yolo11-tut/notebooks/TFT-ID-1\n",
      "Dataset YAML file: /home/terra/projects/yolo11-tut/notebooks/TFT-ID-1/data.yaml\n"
     ]
    }
   ],
   "source": [
    "# Download your dataset from Roboflow\n",
    "import roboflow\n",
    "\n",
    "# Initialize Roboflow with your API key\n",
    "rf = roboflow.Roboflow(api_key=\"f5NyplR2eZarG2ts7Ai5\")\n",
    "\n",
    "workspace_name = \"tokyo-fjwy4\"  # e.g., \"john-doe\" or \"my-company\"\n",
    "project_name = \"tft-id-cjkvr\"  # Your project name\n",
    "version_number = \"1\"  # Your version number\n",
    "\n",
    "# Get your project and dataset\n",
    "project = rf.workspace(workspace_name).project(project_name)\n",
    "dataset = project.version(version_number).download(\"yolov11\")\n",
    "\n",
    "# The dataset will be downloaded to a folder with metadata\n",
    "print(f\"Dataset downloaded to: {dataset.location}\")\n",
    "print(f\"Dataset YAML file: {dataset.location}/data.yaml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40528772",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45a845d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train YOLO with your custom dataset\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLO model\n",
    "model = YOLO(\"yolo11n.pt\")  # nano (fastest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b104f0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.163 ðŸš€ Python-3.12.3 torch-2.7.1+cu126 CPU (12th Gen Intel Core(TM) i5-12450H)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/terra/projects/yolo11-tut/notebooks/TFT-ID-1/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=60, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=custom_yolo_model, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/train/custom_yolo_model, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431257  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,425 parameters, 2,590,409 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 978.4Â±552.1 MB/s, size: 379.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/terra/projects/yolo11-tut/notebooks/TFT-ID-1/train/labels... 35 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:00<00:00, 532.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/terra/projects/yolo11-tut/notebooks/TFT-ID-1/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1591.3Â±146.3 MB/s, size: 353.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/terra/projects/yolo11-tut/notebooks/TFT-ID-1/valid/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 804.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/terra/projects/yolo11-tut/notebooks/TFT-ID-1/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/train/custom_yolo_model/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/custom_yolo_model\u001b[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/60         0G      1.398      3.317      1.478         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:14<00:00,  4.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63     0.0107      0.532     0.0246    0.00868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/60         0G      1.243      3.281      1.441         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.62s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63     0.0128      0.648     0.0474     0.0229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       3/60         0G     0.9927      3.157      1.265         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63     0.0162       0.79      0.209     0.0977\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       4/60         0G     0.8884      3.048      1.234         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63     0.0183      0.842      0.261      0.158\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       5/60         0G     0.8645      2.869       1.17         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63     0.0189      0.904      0.298      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       6/60         0G     0.8147      2.729      1.156         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63     0.0188      0.917      0.322      0.216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       7/60         0G     0.7495      2.727      1.095         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.65s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63     0.0182      0.917      0.328      0.236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/60         0G      0.729      2.629      1.112         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63     0.0181      0.917      0.344      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/60         0G     0.8338      2.564      1.176         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63     0.0183       0.91      0.351      0.245\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      10/60         0G     0.7992      2.506      1.118         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63     0.0186       0.91      0.375      0.256\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      11/60         0G     0.7219      2.325      1.091         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.50s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63     0.0189       0.91      0.455       0.27\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      12/60         0G     0.7033      2.216      1.099         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63     0.0197       0.91      0.502       0.27\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      13/60         0G      0.664      2.132      1.061         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63     0.0202       0.91      0.463       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      14/60         0G     0.7851      1.984      1.129         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63       0.72      0.228       0.46      0.241\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      15/60         0G     0.7098      1.945      1.049         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.847      0.313      0.536      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      16/60         0G     0.7338      1.796      1.085         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.848      0.347      0.578      0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/60         0G     0.7154      1.756      1.089         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.823      0.422      0.616      0.441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      18/60         0G     0.7985      1.724       1.11         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.836      0.504      0.735       0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/60         0G     0.6835      1.633      1.079         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.843      0.494      0.786      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      20/60         0G     0.7835      1.673      1.152         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63       0.81      0.523      0.835      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      21/60         0G     0.6565      1.473       1.05         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.834      0.523      0.808      0.623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      22/60         0G     0.7326      1.514      1.146         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.792      0.535      0.814      0.561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      23/60         0G     0.7626      1.484       1.17         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.735      0.566      0.849      0.573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      24/60         0G     0.7784      1.497      1.136         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.50s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.693      0.637      0.786      0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/60         0G     0.6839      1.474      1.107         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.733      0.739      0.784      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      26/60         0G     0.7184      1.344      1.067         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.691       0.65      0.797      0.606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      27/60         0G     0.7359      1.278      1.087         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.794      0.726      0.869      0.687\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      28/60         0G      0.696      1.297      1.066         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.65s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.689      0.757      0.897      0.664\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      29/60         0G     0.6189      1.241      1.064         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.689      0.757      0.897      0.664\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      30/60         0G     0.7555      1.254      1.117         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.788      0.703      0.862      0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/60         0G     0.6849      1.268      1.087         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.782      0.724      0.789      0.563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      32/60         0G     0.6462      1.195      1.056         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.676      0.741      0.777       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      33/60         0G     0.6322      1.232       1.05         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.676      0.741      0.777       0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/60         0G     0.6284      1.161      1.019         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.628      0.716      0.792        0.6\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      35/60         0G     0.6117      1.206      1.044         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.795      0.835      0.827      0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/60         0G     0.5291      1.011     0.9887         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.872       0.84      0.854      0.654\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      37/60         0G     0.6066       1.08      1.055         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.872       0.84      0.854      0.654\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      38/60         0G     0.5531       1.05       1.02         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63       0.84      0.851      0.842      0.613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      39/60         0G     0.5116     0.9523     0.9723         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.905      0.802      0.838      0.603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      40/60         0G     0.5571      1.024     0.9732         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.763      0.858      0.827      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      41/60         0G     0.5694      1.004      1.037         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.763      0.858      0.827      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      42/60         0G      0.554     0.9116      1.029         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.768      0.851      0.849      0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/60         0G     0.4919     0.9554     0.9696         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.62s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63       0.81      0.847      0.881      0.679\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      44/60         0G     0.4845     0.9686     0.9595         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.81s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.821      0.845      0.916      0.671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/60         0G     0.4794     0.9409     0.9351         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.821      0.845      0.916      0.671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/60         0G     0.5164     0.9174     0.9611         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:10<00:00,  3.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.847      0.857      0.916      0.633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/60         0G     0.4627     0.8692     0.9383         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.833      0.901      0.927      0.643\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      48/60         0G     0.5016      0.881     0.9697         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.842      0.832       0.91       0.66\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      49/60         0G     0.5274     0.8918      0.973         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.842      0.832       0.91       0.66\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      50/60         0G     0.5622      1.073      1.046         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.823      0.846      0.908      0.673\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      51/60         0G     0.5845      1.694      1.115         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.826      0.851      0.887      0.639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      52/60         0G     0.4583      1.411     0.9968         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.843      0.861      0.884      0.639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      53/60         0G     0.5456       1.23       1.08         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:11<00:00,  3.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.843      0.861      0.884      0.639\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      54/60         0G     0.4754      1.022     0.9388         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.869      0.848      0.873      0.679\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      55/60         0G     0.4865      1.239     0.9801         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.848      0.875      0.872      0.699\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      56/60         0G     0.4129       1.03     0.8744         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.852      0.838      0.896      0.675\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      57/60         0G     0.4085      1.093     0.8938         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.852      0.838      0.896      0.675\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      58/60         0G      0.387     0.8916     0.8867         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63       0.87      0.834      0.918      0.679\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      59/60         0G     0.4173      1.274     0.8839          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.918      0.807      0.917       0.67\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      60/60         0G     0.4574     0.8952     0.9117         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.894       0.82      0.907      0.666\n",
      "\n",
      "60 epochs completed in 0.152 hours.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from runs/train/custom_yolo_model/weights/last.pt, 5.5MB\n",
      "Optimizer stripped from runs/train/custom_yolo_model/weights/best.pt, 5.5MB\n",
      "\n",
      "Validating runs/train/custom_yolo_model/weights/best.pt...\n",
      "Ultralytics 8.3.163 ðŸš€ Python-3.12.3 torch-2.7.1+cu126 CPU (12th Gen Intel Core(TM) i5-12450H)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.848      0.875      0.872      0.699\n",
      "                figure          6          8          1      0.999      0.995      0.861\n",
      "                 table          4          4      0.681       0.75       0.72      0.482\n",
      "                  text         10         51      0.864      0.875      0.901      0.754\n",
      "Speed: 1.6ms preprocess, 47.2ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/train/custom_yolo_model\u001b[0m\n",
      "ðŸ§™Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Train the model on your custom dataset\n",
    "results = model.train(\n",
    "    data=f\"{dataset.location}/data.yaml\",  # Use the downloaded dataset path\n",
    "    epochs=60,                             # Number of training epochs\n",
    "    imgsz=640,                             # Image size\n",
    "    batch=16,                              # Batch size (adjust based on your GPU memory)\n",
    "    device='cpu',                          # GPU device (use 'cpu' if no GPU)\n",
    "    project=\"runs/train\",                  # Where to save training results\n",
    "    name=\"custom_yolo_model\"               # Name for this training run\n",
    ")\n",
    "\n",
    "print(\"ðŸ§™Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbf79c0",
   "metadata": {},
   "source": [
    "### Validation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af1ddb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.163 ðŸš€ Python-3.12.3 torch-2.7.1+cu126 CPU (12th Gen Intel Core(TM) i5-12450H)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n summary (fused): 100 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1066.5Â±550.7 MB/s, size: 274.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/terra/projects/yolo11-tut/notebooks/TFT-ID-1/valid/labels.cache... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         63      0.848      0.875      0.872      0.699\n",
      "                figure          6          8          1      0.999      0.995      0.861\n",
      "                 table          4          4      0.681       0.75       0.72      0.482\n",
      "                  text         10         51      0.864      0.875      0.901      0.754\n",
      "Speed: 0.9ms preprocess, 45.3ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/train/custom_yolo_model2\u001b[0m\n",
      "mAP@0.5: 0.8720904755153637\n",
      "mAP@0.5:0.95: 0.699290605276311\n",
      "Precision: 0.8484267862703044\n",
      "Recall: 0.8746073093711466\n"
     ]
    }
   ],
   "source": [
    "# Validate the trained model\n",
    "results = model.val(data=f\"{dataset.location}/data.yaml\")\n",
    "\n",
    "# Print validation metrics\n",
    "print(f\"mAP@0.5: {results.box.map50}\")\n",
    "print(f\"mAP@0.5:0.95: {results.box.map}\")\n",
    "print(f\"Precision: {results.box.mp}\")\n",
    "print(f\"Recall: {results.box.mr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e03a218",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60dd4eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found test images in: /home/terra/projects/yolo11-tut/notebooks/TFT-ID-1/test/images\n",
      "\n",
      "image 1/5 /home/terra/projects/yolo11-tut/notebooks/TFT-ID-1/test/images/arxiv_2305_02549_6_png.rf.c076d77f1864eed72b81f14c6ffae5a5.jpg: 640x480 2 tables, 8 texts, 60.6ms\n",
      "image 2/5 /home/terra/projects/yolo11-tut/notebooks/TFT-ID-1/test/images/arxiv_2305_02665_4_png.rf.c88c1cf5abd35af11b2a08fc179b650c.jpg: 640x480 1 figure, 11 texts, 47.5ms\n",
      "image 3/5 /home/terra/projects/yolo11-tut/notebooks/TFT-ID-1/test/images/arxiv_2305_03027_page_9_png.rf.3879f87b64c4184168d4a4d3fdfcd201.jpg: 640x512 1 figure, 4 tables, 8 texts, 70.9ms\n",
      "image 4/5 /home/terra/projects/yolo11-tut/notebooks/TFT-ID-1/test/images/arxiv_2305_03937_page_7_png.rf.4caf6ab033b4c0c82d05fca0a5308457.jpg: 640x480 1 figure, 3 tables, 6 texts, 48.5ms\n",
      "image 5/5 /home/terra/projects/yolo11-tut/notebooks/TFT-ID-1/test/images/arxiv_2305_03981_7_png.rf.e8d001cbe005bfd0b7aacadbeefe47a5.jpg: 640x480 2 figures, 3 tables, 4 texts, 44.0ms\n",
      "Speed: 5.1ms preprocess, 54.3ms inference, 30.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mruns/predict/test_results\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Load your trained model\n",
    "model = YOLO(\"runs/train/custom_yolo_model/weights/best.pt\")\n",
    "\n",
    "# Check if test images exist in your dataset\n",
    "test_images_path = f\"{dataset.location}/test/images\"\n",
    "if os.path.exists(test_images_path):\n",
    "    print(f\"âœ… Found test images in: {test_images_path}\")\n",
    "    \n",
    "    # Run predictions on all test images\n",
    "    results = model.predict(\n",
    "        source=test_images_path,          # Path to your test images folder\n",
    "        save=True,                        # Save results\n",
    "        show=False,                       # Don't display (set to True if you want to see)\n",
    "        conf=0.1,                         # Confidence threshold\n",
    "        project=\"runs/predict\",           # Where to save predictions\n",
    "        name=\"test_results\"               # Name for this prediction run\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b67993df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Detection Summary:\n",
      "  arxiv_2305_03937_page_7_png.rf.4caf6ab033b4c0c82d05fca0a5308457.jpg: 10 detections\n",
      "    - text: 0.98\n",
      "    - text: 0.93\n",
      "    - text: 0.93\n",
      "    - text: 0.91\n",
      "    - text: 0.88\n",
      "    - text: 0.86\n",
      "    - table: 0.61\n",
      "    - text: 0.22\n",
      "    - table: 0.21\n",
      "    - text: 0.10\n",
      "  arxiv_2305_03027_page_9_png.rf.3879f87b64c4184168d4a4d3fdfcd201.jpg: 12 detections\n",
      "    - text: 0.98\n",
      "    - text: 0.98\n",
      "    - text: 0.98\n",
      "    - figure: 0.93\n",
      "    - text: 0.91\n",
      "    - text: 0.87\n",
      "    - text: 0.49\n",
      "    - text: 0.48\n",
      "    - text: 0.37\n",
      "    - text: 0.27\n",
      "    - text: 0.13\n",
      "    - text: 0.11\n",
      "  arxiv_2305_02549_6_png.rf.c076d77f1864eed72b81f14c6ffae5a5.jpg: 13 detections\n",
      "    - text: 0.92\n",
      "    - text: 0.91\n",
      "    - text: 0.85\n",
      "    - text: 0.83\n",
      "    - figure: 0.82\n",
      "    - table: 0.79\n",
      "    - table: 0.78\n",
      "    - text: 0.68\n",
      "    - table: 0.46\n",
      "    - text: 0.43\n",
      "    - table: 0.29\n",
      "    - text: 0.13\n",
      "    - text: 0.12\n",
      "  arxiv_2305_03981_7_png.rf.e8d001cbe005bfd0b7aacadbeefe47a5.jpg: 10 detections\n",
      "    - table: 0.99\n",
      "    - table: 0.98\n",
      "    - text: 0.93\n",
      "    - text: 0.91\n",
      "    - text: 0.89\n",
      "    - text: 0.69\n",
      "    - text: 0.57\n",
      "    - figure: 0.54\n",
      "    - table: 0.27\n",
      "    - text: 0.19\n",
      "  arxiv_2305_02665_4_png.rf.c88c1cf5abd35af11b2a08fc179b650c.jpg: 9 detections\n",
      "    - table: 0.98\n",
      "    - text: 0.97\n",
      "    - text: 0.93\n",
      "    - figure: 0.93\n",
      "    - text: 0.91\n",
      "    - figure: 0.79\n",
      "    - table: 0.40\n",
      "    - text: 0.13\n",
      "    - table: 0.10\n",
      "\n",
      "ðŸŽ¯ Model classes: ['figure', 'table', 'text']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "test_images_path = f\"{dataset.location}/test/images\"\n",
    "test_image_files = glob.glob(f\"{test_images_path}/*.jpg\") + glob.glob(f\"{test_images_path}/*.png\")\n",
    "\n",
    "\n",
    "# Find prediction results directory\n",
    "pred_dirs = glob.glob(\"runs/predict/test_results_plot*\")\n",
    "if pred_dirs:\n",
    "    pred_path = max(pred_dirs, key=os.path.getmtime)\n",
    "    print(f\"ðŸ“ Using predictions from: {pred_path}\")\n",
    "else:\n",
    "    pred_path = \"runs/predict/test_results_plot\"\n",
    "\n",
    "\n",
    "print(\"\\nðŸ“Š Detection Summary:\")\n",
    "for i in range(len(results)):\n",
    "    img_name = os.path.basename(test_image_files[i])\n",
    "    result = results[i]\n",
    "    num_detections = len(result.boxes) if result.boxes is not None else 0\n",
    "    print(f\"  {img_name}: {num_detections} detections\")\n",
    "    \n",
    "    if num_detections > 0:\n",
    "        for j, box in enumerate(result.boxes):\n",
    "            confidence = box.conf.item()\n",
    "            class_id = int(box.cls.item())\n",
    "            class_name = model.names[class_id]\n",
    "            print(f\"    - {class_name}: {confidence:.2f}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Model classes: {list(model.names.values())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36485845",
   "metadata": {},
   "source": [
    "Predictions:\n",
    "1. YOLO's built-in annotation when saving images\n",
    "2. YOLO uses white/light backgrounds by default for text readability --> different from labeled image plot color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc63a917",
   "metadata": {},
   "source": [
    "### Plotting the test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b5dfb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Found 5 test images\n",
      "ðŸ“ Using prediction results from: runs/predict/test_results\n",
      "ðŸ“Š Creating visualization grid: 5 rows Ã— 3 columns\n",
      "\n",
      "ðŸ“¸ Processing image 1/5: arxiv_2305_02549_6_png.rf.c076d77f1864eed72b81f14c6ffae5a5.jpg\n",
      "  Ground truth: 7 objects\n",
      "  âœ… Found prediction image\n",
      "\n",
      "ðŸ“¸ Processing image 2/5: arxiv_2305_02665_4_png.rf.c88c1cf5abd35af11b2a08fc179b650c.jpg\n",
      "  Ground truth: 5 objects\n",
      "  âœ… Found prediction image\n",
      "\n",
      "ðŸ“¸ Processing image 3/5: arxiv_2305_03027_page_9_png.rf.3879f87b64c4184168d4a4d3fdfcd201.jpg\n",
      "  Ground truth: 8 objects\n",
      "  âœ… Found prediction image\n",
      "\n",
      "ðŸ“¸ Processing image 4/5: arxiv_2305_03937_page_7_png.rf.4caf6ab033b4c0c82d05fca0a5308457.jpg\n",
      "  Ground truth: 8 objects\n",
      "  âœ… Found prediction image\n",
      "\n",
      "ðŸ“¸ Processing image 5/5: arxiv_2305_03981_7_png.rf.e8d001cbe005bfd0b7aacadbeefe47a5.jpg\n",
      "  Ground truth: 6 objects\n",
      "  âœ… Found prediction image\n",
      "\n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Figure saved as 'runs/predict/test_comparison.png'\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š GROUND TRUTH SUMMARY\n",
      "============================================================\n",
      "Total Ground Truth Objects: 34\n",
      "\n",
      "Class-wise Ground Truth Count:\n",
      "  figure  :  6 objects\n",
      "  table   :  7 objects\n",
      "  text    : 21 objects\n",
      "\n",
      "âœ… Visualization complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "# Configure matplotlib for Jupyter notebook\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive backend\n",
    "plt.ioff()  # Turn off interactive mode\n",
    "\n",
    "# Class names and colors for visualization\n",
    "class_names = ['figure', 'table', 'text']\n",
    "colors = ['red', 'blue', 'green']\n",
    "color_map = {i: colors[i] for i in range(len(class_names))}\n",
    "\n",
    "def parse_yolo_label(label_file, img_width, img_height):\n",
    "    \"\"\"Parse YOLO format label file and return bounding boxes\"\"\"\n",
    "    boxes = []\n",
    "    if os.path.exists(label_file):\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    x_center = float(parts[1]) * img_width\n",
    "                    y_center = float(parts[2]) * img_height\n",
    "                    width = float(parts[3]) * img_width\n",
    "                    height = float(parts[4]) * img_height\n",
    "                    \n",
    "                    # Convert to top-left corner format\n",
    "                    x1 = x_center - width/2\n",
    "                    y1 = y_center - height/2\n",
    "                    x2 = x_center + width/2\n",
    "                    y2 = y_center + height/2\n",
    "                    \n",
    "                    boxes.append({\n",
    "                        'class_id': class_id,\n",
    "                        'class_name': class_names[class_id],\n",
    "                        'bbox': [x1, y1, x2, y2],\n",
    "                        'confidence': 1.0  # Ground truth has 100% confidence\n",
    "                    })\n",
    "    return boxes\n",
    "\n",
    "def load_prediction_results():\n",
    "    \"\"\"Load existing prediction results from runs/predict folder\"\"\"\n",
    "    pred_dirs = glob.glob(\"runs/predict/test_results*\")\n",
    "    if not pred_dirs:\n",
    "        print(\"âŒ No prediction results found! Please run predictions first.\")\n",
    "        return None\n",
    "    \n",
    "    # Use the latest prediction directory\n",
    "    pred_dir = max(pred_dirs, key=os.path.getmtime)\n",
    "    print(f\"ðŸ“ Using prediction results from: {pred_dir}\")\n",
    "    \n",
    "    # Find prediction images\n",
    "    pred_images = glob.glob(f\"{pred_dir}/*.jpg\") + glob.glob(f\"{pred_dir}/*.png\")\n",
    "    if not pred_images:\n",
    "        print(f\"âŒ No prediction images found in {pred_dir}\")\n",
    "        return None\n",
    "    \n",
    "    return pred_dir\n",
    "\n",
    "def draw_boxes(ax, boxes, title, img_width, img_height):\n",
    "    \"\"\"Draw bounding boxes on the image\"\"\"\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.set_xlim(0, img_width)\n",
    "    ax.set_ylim(img_height, 0)  # Flip y-axis for image coordinates\n",
    "    \n",
    "    for box in boxes:\n",
    "        class_id = box['class_id']\n",
    "        class_name = box['class_name']\n",
    "        bbox = box['bbox']\n",
    "        confidence = box['confidence']\n",
    "        \n",
    "        x1, y1, x2, y2 = bbox\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        \n",
    "        # Draw rectangle\n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), width, height, \n",
    "            linewidth=2, \n",
    "            edgecolor=color_map[class_id], \n",
    "            facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add label\n",
    "        label = f\"{class_name}: {confidence:.2f}\"\n",
    "        ax.text(x1, y1-5, label, \n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=color_map[class_id], alpha=0.7),\n",
    "                fontsize=10, color='white', weight='bold')\n",
    "\n",
    "# Get test images and labels\n",
    "test_images_path = f\"{dataset.location}/test/images\"\n",
    "test_labels_path = f\"{dataset.location}/test/labels\"\n",
    "\n",
    "test_image_files = sorted(glob.glob(f\"{test_images_path}/*.jpg\") + glob.glob(f\"{test_images_path}/*.png\"))\n",
    "print(f\"ðŸ“ Found {len(test_image_files)} test images\")\n",
    "\n",
    "# Load prediction results\n",
    "pred_dir = load_prediction_results()\n",
    "if pred_dir is None:\n",
    "    print(\"âŒ Cannot proceed without prediction results!\")\n",
    "    exit()\n",
    "\n",
    "# Create comparison plots with smaller, more manageable size\n",
    "fig_width = 15\n",
    "fig_height = 4 * len(test_image_files)\n",
    "fig, axes = plt.subplots(len(test_image_files), 3, figsize=(fig_width, fig_height))\n",
    "\n",
    "if len(test_image_files) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "print(f\"ðŸ“Š Creating visualization grid: {len(test_image_files)} rows Ã— 3 columns\")\n",
    "\n",
    "for i, img_path in enumerate(test_image_files):\n",
    "    print(f\"\\nðŸ“¸ Processing image {i+1}/{len(test_image_files)}: {os.path.basename(img_path)}\")\n",
    "    \n",
    "    # Load original image\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_width, img_height = img.size\n",
    "    \n",
    "    # Get image filename without extension for label file\n",
    "    img_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    label_file = os.path.join(test_labels_path, f\"{img_name}.txt\")\n",
    "    \n",
    "    # Parse ground truth labels\n",
    "    gt_boxes = parse_yolo_label(label_file, img_width, img_height)\n",
    "    print(f\"  Ground truth: {len(gt_boxes)} objects\")\n",
    "    \n",
    "    # Find corresponding prediction image\n",
    "    pred_image_path = os.path.join(pred_dir, os.path.basename(img_path))\n",
    "    if os.path.exists(pred_image_path):\n",
    "        pred_img = Image.open(pred_image_path).convert('RGB')\n",
    "        print(f\"  âœ… Found prediction image\")\n",
    "    else:\n",
    "        pred_img = img  # Use original if prediction not found\n",
    "        print(f\"  âš ï¸ Prediction image not found, using original\")\n",
    "    \n",
    "    # Plot original image\n",
    "    axes[i][0].imshow(img)\n",
    "    axes[i][0].set_title(f\"Original Image\\n{os.path.basename(img_path)}\", fontsize=12)\n",
    "    axes[i][0].axis('off')\n",
    "    \n",
    "    # Plot ground truth\n",
    "    axes[i][1].imshow(img)\n",
    "    draw_boxes(axes[i][1], gt_boxes, f\"Ground Truth\\n{len(gt_boxes)} objects\", img_width, img_height)\n",
    "    axes[i][1].axis('off')\n",
    "    \n",
    "    # Plot prediction image (with annotations already drawn by YOLO)\n",
    "    axes[i][2].imshow(pred_img)\n",
    "    axes[i][2].set_title(f\"Predictions\\n(with annotations)\", fontsize=12)\n",
    "    axes[i][2].axis('off')\n",
    "\n",
    "# Add legend\n",
    "legend_elements = [patches.Patch(color=color_map[i], label=class_names[i]) for i in range(len(class_names))]\n",
    "fig.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(0.98, 0.98))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Test Images: Ground Truth vs Predictions', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "# Save the figure to ensure it's created\n",
    "plt.savefig('runs/predict/test_comparison.png', dpi=150, bbox_inches='tight')\n",
    "print()\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ’¾ Figure saved as 'runs/predict/test_comparison.png'\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Print summary statistics for ground truth\n",
    "print()\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ“Š GROUND TRUTH SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_gt = 0\n",
    "class_gt_counts = {name: 0 for name in class_names}\n",
    "\n",
    "for i, img_path in enumerate(test_image_files):\n",
    "    img_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    label_file = os.path.join(test_labels_path, f\"{img_name}.txt\")\n",
    "    \n",
    "    # Count ground truth objects\n",
    "    img = Image.open(img_path)\n",
    "    img_width, img_height = img.size\n",
    "    gt_boxes = parse_yolo_label(label_file, img_width, img_height)\n",
    "    \n",
    "    total_gt += len(gt_boxes)\n",
    "    \n",
    "    # Count by class\n",
    "    for box in gt_boxes:\n",
    "        class_gt_counts[box['class_name']] += 1\n",
    "\n",
    "print(f\"Total Ground Truth Objects: {total_gt}\")\n",
    "\n",
    "print(f\"\\nClass-wise Ground Truth Count:\")\n",
    "for class_name in class_names:\n",
    "    gt_count = class_gt_counts[class_name]\n",
    "    print(f\"  {class_name:8}: {gt_count:2d} objects\")\n",
    "\n",
    "print(\"\\nâœ… Visualization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07f1d94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Re-running predictions to get detection data...\n",
      "âœ… Got prediction results for 5 images\n",
      "\n",
      "ðŸ“Š Prediction Summary:\n",
      "  arxiv_2305_02549_6_png.rf.c076d77f1864eed72b81f14c6ffae5a5.jpg: 10 detections\n",
      "    - text: 0.98\n",
      "    - text: 0.93\n",
      "    - text: 0.93\n",
      "    - text: 0.91\n",
      "    - text: 0.88\n",
      "    - text: 0.86\n",
      "    - table: 0.61\n",
      "    - text: 0.22\n",
      "    - table: 0.21\n",
      "    - text: 0.10\n",
      "  arxiv_2305_02665_4_png.rf.c88c1cf5abd35af11b2a08fc179b650c.jpg: 12 detections\n",
      "    - text: 0.98\n",
      "    - text: 0.98\n",
      "    - text: 0.98\n",
      "    - figure: 0.93\n",
      "    - text: 0.91\n",
      "    - text: 0.87\n",
      "    - text: 0.49\n",
      "    - text: 0.48\n",
      "    - text: 0.37\n",
      "    - text: 0.27\n",
      "    - text: 0.13\n",
      "    - text: 0.11\n",
      "  arxiv_2305_03027_page_9_png.rf.3879f87b64c4184168d4a4d3fdfcd201.jpg: 13 detections\n",
      "    - text: 0.92\n",
      "    - text: 0.91\n",
      "    - text: 0.85\n",
      "    - text: 0.83\n",
      "    - figure: 0.82\n",
      "    - table: 0.79\n",
      "    - table: 0.78\n",
      "    - text: 0.68\n",
      "    - table: 0.46\n",
      "    - text: 0.43\n",
      "    - table: 0.29\n",
      "    - text: 0.13\n",
      "    - text: 0.12\n",
      "  arxiv_2305_03937_page_7_png.rf.4caf6ab033b4c0c82d05fca0a5308457.jpg: 10 detections\n",
      "    - table: 0.99\n",
      "    - table: 0.98\n",
      "    - text: 0.93\n",
      "    - text: 0.91\n",
      "    - text: 0.89\n",
      "    - text: 0.69\n",
      "    - text: 0.57\n",
      "    - figure: 0.54\n",
      "    - table: 0.27\n",
      "    - text: 0.19\n",
      "  arxiv_2305_03981_7_png.rf.e8d001cbe005bfd0b7aacadbeefe47a5.jpg: 9 detections\n",
      "    - table: 0.98\n",
      "    - text: 0.97\n",
      "    - text: 0.93\n",
      "    - figure: 0.93\n",
      "    - text: 0.91\n",
      "    - figure: 0.79\n",
      "    - table: 0.40\n",
      "    - text: 0.13\n",
      "    - table: 0.10\n",
      "\n",
      "Total Predictions: 54\n",
      "  figure: 5 objects\n",
      "  table: 12 objects\n",
      "  text: 37 objects\n",
      "\n",
      "ðŸ” Creating confusion matrix with IoU threshold: 0.5\n",
      "ðŸ“¸ Processing 1/5: arxiv_2305_02549_6_png.rf.c076d77f1864eed72b81f14c6ffae5a5.jpg\n",
      "  Ground truth: 7 objects | Predictions: 10 objects\n",
      "ðŸ“¸ Processing 2/5: arxiv_2305_02665_4_png.rf.c88c1cf5abd35af11b2a08fc179b650c.jpg\n",
      "  Ground truth: 5 objects | Predictions: 12 objects\n",
      "ðŸ“¸ Processing 3/5: arxiv_2305_03027_page_9_png.rf.3879f87b64c4184168d4a4d3fdfcd201.jpg\n",
      "  Ground truth: 8 objects | Predictions: 13 objects\n",
      "ðŸ“¸ Processing 4/5: arxiv_2305_03937_page_7_png.rf.4caf6ab033b4c0c82d05fca0a5308457.jpg\n",
      "  Ground truth: 8 objects | Predictions: 10 objects\n",
      "ðŸ“¸ Processing 5/5: arxiv_2305_03981_7_png.rf.e8d001cbe005bfd0b7aacadbeefe47a5.jpg\n",
      "  Ground truth: 6 objects | Predictions: 9 objects\n",
      "ðŸ’¾ Confusion matrix saved as 'runs/predict/confusion_matrix.png'\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š CONFUSION MATRIX ANALYSIS\n",
      "============================================================\n",
      "Total Ground Truth Objects: 34\n",
      "Total Predicted Objects: 54\n",
      "Total Matches (IoU â‰¥ 0.5): 33\n",
      "Overall Precision: 0.611\n",
      "Overall Recall: 0.971\n",
      "\n",
      "Per-Class Metrics:\n",
      "Class      TP   FP   FN   Precision  Recall     F1-Score  \n",
      "----------------------------------------------------------------------\n",
      "figure     5    0    0    1.000      1.000      1.000     \n",
      "table      6    5    1    0.545      0.857      0.667     \n",
      "text       21   16   0    0.568      1.000      0.724     \n",
      "\n",
      "âœ… Confusion matrix analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix - Using Actual Model Results, not searching for non-existant predicted label files\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# Set up matplotlib\n",
    "try:\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')  # Use non-interactive backend\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Variables from previous cells\n",
    "class_names = ['figure', 'table', 'text']\n",
    "test_images_path = f\"{dataset.location}/test/images\"\n",
    "test_labels_path = f\"{dataset.location}/test/labels\"\n",
    "test_image_files = sorted(glob.glob(f\"{test_images_path}/*.jpg\") + glob.glob(f\"{test_images_path}/*.png\"))\n",
    "\n",
    "# Re-run predictions to get actual results data (not just images)\n",
    "print(\"ðŸ”„ Re-running predictions to get detection data...\")\n",
    "\n",
    "# Load the trained model\n",
    "model = YOLO(\"runs/train/custom_yolo_model/weights/best.pt\")\n",
    "\n",
    "# Run predictions on test images to get actual results\n",
    "results = model.predict(\n",
    "    source=test_images_path,\n",
    "    save=False,  # Don't save images, just get results\n",
    "    show=False,\n",
    "    conf=0.1,  # Same confidence threshold as original\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"âœ… Got prediction results for {len(results)} images\")\n",
    "\n",
    "# Print prediction summary to match test results\n",
    "print(\"\\nðŸ“Š Prediction Summary:\")\n",
    "total_predictions = 0\n",
    "class_pred_counts = {name: 0 for name in class_names}\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    img_name = os.path.basename(test_image_files[i])\n",
    "    num_detections = len(result.boxes) if result.boxes is not None else 0\n",
    "    total_predictions += num_detections\n",
    "    print(f\"  {img_name}: {num_detections} detections\")\n",
    "    \n",
    "    if num_detections > 0:\n",
    "        for box in result.boxes:\n",
    "            class_id = int(box.cls.item())\n",
    "            class_name = class_names[class_id]\n",
    "            class_pred_counts[class_name] += 1\n",
    "            confidence = box.conf.item()\n",
    "            print(f\"    - {class_name}: {confidence:.2f}\")\n",
    "\n",
    "print(f\"\\nTotal Predictions: {total_predictions}\")\n",
    "for class_name in class_names:\n",
    "    count = class_pred_counts[class_name]\n",
    "    print(f\"  {class_name}: {count} objects\")\n",
    "\n",
    "# Helper functions\n",
    "def parse_yolo_label(label_file, img_width, img_height):\n",
    "    \"\"\"Parse YOLO format label file and return bounding boxes\"\"\"\n",
    "    boxes = []\n",
    "    if os.path.exists(label_file):\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    x_center = float(parts[1]) * img_width\n",
    "                    y_center = float(parts[2]) * img_height\n",
    "                    width = float(parts[3]) * img_width\n",
    "                    height = float(parts[4]) * img_height\n",
    "                    \n",
    "                    # Convert to top-left corner format\n",
    "                    x1 = x_center - width/2\n",
    "                    y1 = y_center - height/2\n",
    "                    x2 = x_center + width/2\n",
    "                    y2 = y_center + height/2\n",
    "                    \n",
    "                    boxes.append({\n",
    "                        'class_id': class_id,\n",
    "                        'class_name': class_names[class_id],\n",
    "                        'bbox': [x1, y1, x2, y2],\n",
    "                        'confidence': 1.0  # Ground truth has 100% confidence\n",
    "                    })\n",
    "    return boxes\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calculate Intersection over Union (IoU) of two bounding boxes\"\"\"\n",
    "    # box format: [x1, y1, x2, y2]\n",
    "    x1_1, y1_1, x2_1, y2_1 = box1\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2\n",
    "    \n",
    "    # Calculate intersection coordinates\n",
    "    x1_inter = max(x1_1, x1_2)\n",
    "    y1_inter = max(y1_1, y1_2)\n",
    "    x2_inter = min(x2_1, x2_2)\n",
    "    y2_inter = min(y2_1, y2_2)\n",
    "    \n",
    "    # Calculate intersection area\n",
    "    if x2_inter <= x1_inter or y2_inter <= y1_inter:\n",
    "        intersection = 0\n",
    "    else:\n",
    "        intersection = (x2_inter - x1_inter) * (y2_inter - y1_inter)\n",
    "    \n",
    "    # Calculate areas of both boxes\n",
    "    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "    \n",
    "    # Calculate union area\n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    # Calculate IoU\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union\n",
    "\n",
    "def match_predictions_to_ground_truth(gt_boxes, pred_boxes, iou_threshold=0.5):\n",
    "    \"\"\"Match predictions to ground truth boxes using IoU threshold\"\"\"\n",
    "    matches = []\n",
    "    matched_gt = set()\n",
    "    matched_pred = set()\n",
    "    \n",
    "    # Sort predictions by confidence (highest first)\n",
    "    pred_boxes_sorted = sorted(enumerate(pred_boxes), key=lambda x: x[1]['confidence'], reverse=True)\n",
    "    \n",
    "    for pred_idx, pred_box in pred_boxes_sorted:\n",
    "        if pred_idx in matched_pred:\n",
    "            continue\n",
    "            \n",
    "        best_iou = 0\n",
    "        best_gt_idx = -1\n",
    "        \n",
    "        # Find best matching ground truth box\n",
    "        for gt_idx, gt_box in enumerate(gt_boxes):\n",
    "            if gt_idx in matched_gt:\n",
    "                continue\n",
    "                \n",
    "            iou = calculate_iou(pred_box['bbox'], gt_box['bbox'])\n",
    "            \n",
    "            if iou > best_iou and iou >= iou_threshold:\n",
    "                best_iou = iou\n",
    "                best_gt_idx = gt_idx\n",
    "        \n",
    "        if best_gt_idx != -1:\n",
    "            matches.append({\n",
    "                'pred_idx': pred_idx,\n",
    "                'gt_idx': best_gt_idx,\n",
    "                'pred_class': pred_box['class_id'],\n",
    "                'gt_class': gt_boxes[best_gt_idx]['class_id'],\n",
    "                'iou': best_iou,\n",
    "                'confidence': pred_box['confidence']\n",
    "            })\n",
    "            matched_gt.add(best_gt_idx)\n",
    "            matched_pred.add(pred_idx)\n",
    "    \n",
    "    return matches, matched_gt, matched_pred\n",
    "\n",
    "def create_confusion_matrix(iou_threshold=0.5):\n",
    "    \"\"\"Create confusion matrix for object detection results\"\"\"\n",
    "    print(f\"\\nðŸ” Creating confusion matrix with IoU threshold: {iou_threshold}\")\n",
    "    \n",
    "    # Initialize confusion matrix\n",
    "    num_classes = len(class_names)\n",
    "    confusion_matrix = np.zeros((num_classes + 1, num_classes + 1), dtype=int)\n",
    "    \n",
    "    # Class names with background\n",
    "    class_names_with_bg = class_names + ['background']\n",
    "    \n",
    "    # Statistics\n",
    "    total_gt = 0\n",
    "    total_pred = 0\n",
    "    total_matches = 0\n",
    "    \n",
    "    # Process each test image\n",
    "    for i, img_path in enumerate(test_image_files):\n",
    "        print(f\"ðŸ“¸ Processing {i+1}/{len(test_image_files)}: {os.path.basename(img_path)}\")\n",
    "        \n",
    "        # Load image dimensions\n",
    "        img = Image.open(img_path)\n",
    "        img_width, img_height = img.size\n",
    "        \n",
    "        # Get ground truth boxes\n",
    "        img_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        label_file = os.path.join(test_labels_path, f\"{img_name}.txt\")\n",
    "        gt_boxes = parse_yolo_label(label_file, img_width, img_height)\n",
    "        \n",
    "        # Get prediction boxes from model results\n",
    "        result = results[i]\n",
    "        pred_boxes = []\n",
    "        \n",
    "        if result.boxes is not None:\n",
    "            for box in result.boxes:\n",
    "                # Get box coordinates (already in pixel coordinates)\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                class_id = int(box.cls.item())\n",
    "                confidence = box.conf.item()\n",
    "                \n",
    "                pred_boxes.append({\n",
    "                    'class_id': class_id,\n",
    "                    'class_name': class_names[class_id],\n",
    "                    'bbox': [x1, y1, x2, y2],\n",
    "                    'confidence': confidence\n",
    "                })\n",
    "        \n",
    "        total_gt += len(gt_boxes)\n",
    "        total_pred += len(pred_boxes)\n",
    "        \n",
    "        print(f\"  Ground truth: {len(gt_boxes)} objects | Predictions: {len(pred_boxes)} objects\")\n",
    "        \n",
    "        # Match predictions to ground truth\n",
    "        matches, matched_gt, matched_pred = match_predictions_to_ground_truth(\n",
    "            gt_boxes, pred_boxes, iou_threshold\n",
    "        )\n",
    "        \n",
    "        total_matches += len(matches)\n",
    "        \n",
    "        # Update confusion matrix\n",
    "        # True positives and false positives\n",
    "        for match in matches:\n",
    "            gt_class = match['gt_class']\n",
    "            pred_class = match['pred_class']\n",
    "            confusion_matrix[gt_class, pred_class] += 1\n",
    "        \n",
    "        # False positives (unmatched predictions)\n",
    "        for pred_idx, pred_box in enumerate(pred_boxes):\n",
    "            if pred_idx not in matched_pred:\n",
    "                pred_class = pred_box['class_id']\n",
    "                confusion_matrix[num_classes, pred_class] += 1  # background -> predicted class\n",
    "        \n",
    "        # False negatives (unmatched ground truth)\n",
    "        for gt_idx, gt_box in enumerate(gt_boxes):\n",
    "            if gt_idx not in matched_gt:\n",
    "                gt_class = gt_box['class_id']\n",
    "                confusion_matrix[gt_class, num_classes] += 1  # true class -> background\n",
    "    \n",
    "    return confusion_matrix, class_names_with_bg, total_gt, total_pred, total_matches\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, class_names_with_bg, title=\"Confusion Matrix\"):\n",
    "    \"\"\"Plot confusion matrix with nice formatting\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(\n",
    "        confusion_matrix,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='Blues',\n",
    "        xticklabels=class_names_with_bg,\n",
    "        yticklabels=class_names_with_bg,\n",
    "        square=True,\n",
    "        cbar_kws={'label': 'Count'}\n",
    "    )\n",
    "    \n",
    "    plt.title(title, fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Predicted Class', fontsize=12)\n",
    "    plt.ylabel('True Class', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    # Add text explanation\n",
    "    plt.figtext(0.02, 0.02, \n",
    "                'Note: \"background\" represents unmatched predictions (false positives) or ground truth (false negatives)',\n",
    "                fontsize=10, style='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "# Create confusion matrix\n",
    "confusion_matrix, class_names_with_bg, total_gt, total_pred, total_matches = create_confusion_matrix(iou_threshold=0.5)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(confusion_matrix, class_names_with_bg, \"Object Detection Confusion Matrix (IoU â‰¥ 0.5)\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs('runs/predict', exist_ok=True)\n",
    "plt.savefig('runs/predict/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "print(\"ðŸ’¾ Confusion matrix saved as 'runs/predict/confusion_matrix.png'\")\n",
    "\n",
    "# Calculate and display metrics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“Š CONFUSION MATRIX ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Total Ground Truth Objects: {total_gt}\")\n",
    "print(f\"Total Predicted Objects: {total_pred}\")\n",
    "print(f\"Total Matches (IoU â‰¥ 0.5): {total_matches}\")\n",
    "print(f\"Overall Precision: {total_matches/total_pred:.3f}\" if total_pred > 0 else \"Overall Precision: N/A\")\n",
    "print(f\"Overall Recall: {total_matches/total_gt:.3f}\" if total_gt > 0 else \"Overall Recall: N/A\")\n",
    "\n",
    "# Per-class metrics\n",
    "print(f\"\\nPer-Class Metrics:\")\n",
    "print(f\"{'Class':<10} {'TP':<4} {'FP':<4} {'FN':<4} {'Precision':<10} {'Recall':<10} {'F1-Score':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    tp = confusion_matrix[i, i]  # True positives\n",
    "    fp = confusion_matrix[-1, i]  # False positives (background -> predicted as this class)\n",
    "    fn = confusion_matrix[i, -1]  # False negatives (this class -> predicted as background)\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(f\"{class_name:<10} {tp:<4} {fp:<4} {fn:<4} {precision:<10.3f} {recall:<10.3f} {f1:<10.3f}\")\n",
    "\n",
    "print(\"\\nâœ… Confusion matrix analysis complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo11-tut-RRLyLOEp-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
